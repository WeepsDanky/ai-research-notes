# PEFT Adapters

## Low Rank Adaption (LoRA) 

A popular technique to reduce number of trainable parameters. Approximate weights to low rank matrix. 

> E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,” arXiv preprint arXiv:2106.09685, 2021.